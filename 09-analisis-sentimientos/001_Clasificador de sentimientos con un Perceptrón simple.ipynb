{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvOZ6g1+dXIgVwi7uJf1eh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Perceptrón para Análisis de Sentimiento en Español\n","\n","##Objetivo\n","\n","En esta actividad vas a implementar desde cero un modelo de Perceptrón en Python usando solo NumPy. Vamos a entrenarlo con frases breves escritas en español rioplatense para que aprenda a reconocer si una frase tiene un sentimiento positivo o negativo.\n","\n","El objetivo es entender cómo funciona una neurona artificial básica, cómo se ajustan sus pesos durante el aprendizaje, y cómo puede hacer predicciones en base a un conjunto pequeño de frases."],"metadata":{"id":"7Wp1oHfMVm7G"}},{"cell_type":"markdown","source":["##📚 1. Datos de entrenamiento\n","Vamos a usar un pequeño conjunto de frases etiquetadas como positivas (1) o negativas (0). Las frases son simples como las que podríamos encontrar en una conversación cotidiana.\n","\n","También definimos un vocabulario básico de palabras clave que aparecen con frecuencia y que nos pueden ayudar a inferir el sentimiento."],"metadata":{"id":"dgAH1ajRV1qj"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Frases con su etiqueta de sentimiento (1 = positivo, 0 = negativo)\n","frases = [\n","    \"Amo el verano en Buenos Aires\",\n","    \"No me gusta el tráfico matutino\",\n","    \"Este asado está espectacular\",\n","    \"Qué bajón, perdí el colectivo\",\n","    \"Me encanta salir los domingos\",\n","    \"Detesto el calor húmedo\"\n","]\n","\n","etiquetas = np.array([1, 0, 1, 0, 1, 0])  # Etiquetas\n","\n","# Vocabulario manual con palabras claves de carga emocional\n","vocabulario = [\"amo\", \"no\", \"gusta\", \"asado\", \"espectacular\", \"bajón\", \"perdí\", \"detesto\", \"calor\", \"húmedo\"]\n"],"metadata":{"id":"9vX8U_tNV1IU","executionInfo":{"status":"ok","timestamp":1747951981110,"user_tz":180,"elapsed":6,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["##🧰 2. Representación numérica: Vectorización de frases\n","Vamos a convertir cada frase en un vector binario que indica si una palabra del vocabulario aparece o no."],"metadata":{"id":"LvsP06NiWJ70"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"bVqKwVqzVHHx","executionInfo":{"status":"ok","timestamp":1747952067626,"user_tz":180,"elapsed":29,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}}},"outputs":[],"source":["# Función que convierte una frase en un vector binario según el vocabulario\n","def vectorizar(frase, vocabulario):\n","    tokens = frase.lower().split()\n","    return np.array([1 if palabra in tokens else 0 for palabra in vocabulario])\n","\n","# Aplicamos la función a todas las frases\n","X = np.array([vectorizar(frase, vocabulario) for frase in frases])\n"]},{"cell_type":"markdown","source":["##🧠 3. Definición del modelo: el Perceptrón\n","Un perceptrón es una función que:\n","\n","* Multiplica cada entrada por un peso.\n","\n","* Suma los resultados y agrega un sesgo (bias).\n","\n","* Aplica una función de activación (en este caso, escalón) para decidir si \"dispara\" o no.\n","\n","Vamos a inicializar los pesos aleatoriamente y entrenar el modelo para que aprenda de los errores."],"metadata":{"id":"rDflDIhAWfJb"}},{"cell_type":"code","source":["# Inicializamos pesos y bias\n","np.random.seed(42)\n","pesos = np.random.randn(len(vocabulario))\n","bias = 0.0\n","\n","# Función de activación (escalón)\n","def activar(suma):\n","    return 1 if suma > 0 else 0\n","\n","# Función de predicción\n","def predecir(x):\n","    suma = np.dot(x, pesos) + bias\n","    return activar(suma)"],"metadata":{"id":"zU2tI5lmWnUM","executionInfo":{"status":"ok","timestamp":1747952348484,"user_tz":180,"elapsed":9,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["##🔁 4. Entrenamiento del modelo\n","Ahora vamos a entrenar el perceptrón ajustando los pesos según los errores que comete. Usamos la regla de aprendizaje del perceptrón: si se equivoca, ajusta los pesos y el sesgo para acercarse al resultado correcto."],"metadata":{"id":"LYUYudh9Wwxb"}},{"cell_type":"code","source":["# Parámetros de entrenamiento\n","tasa_aprendizaje = 0.1\n","epocas = 20\n","\n","# Bucle de entrenamiento\n","for epoca in range(epocas):\n","    errores = 0\n","    for i in range(len(X)):\n","        x_i = X[i]\n","        y_real = etiquetas[i]\n","        y_pred = predecir(x_i)\n","        error = y_real - y_pred\n","        if error != 0:\n","            pesos += tasa_aprendizaje * error * x_i\n","            bias += tasa_aprendizaje * error\n","            errores += 1\n","    print(f\"Época {epoca + 1}: Errores = {errores}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvSf_KjeW06z","executionInfo":{"status":"ok","timestamp":1747952503725,"user_tz":180,"elapsed":12,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"1c2d8a2e-105a-44c5-b9c0-ef687bcacb39"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Época 1: Errores = 2\n","Época 2: Errores = 2\n","Época 3: Errores = 1\n","Época 4: Errores = 2\n","Época 5: Errores = 2\n","Época 6: Errores = 1\n","Época 7: Errores = 2\n","Época 8: Errores = 1\n","Época 9: Errores = 2\n","Época 10: Errores = 2\n","Época 11: Errores = 1\n","Época 12: Errores = 2\n","Época 13: Errores = 2\n","Época 14: Errores = 1\n","Época 15: Errores = 2\n","Época 16: Errores = 2\n","Época 17: Errores = 0\n","Época 18: Errores = 0\n","Época 19: Errores = 0\n","Época 20: Errores = 0\n"]}]},{"cell_type":"markdown","source":["##🧪 5. Prueba con nuevas frases\n","Ahora vamos a ver cómo se comporta nuestro perceptrón con frases nuevas que no vio durante el entrenamiento."],"metadata":{"id":"MjOdY0DRW-Ms"}},{"cell_type":"code","source":["# Frases nuevas para testeo\n","frases_prueba = [\n","    \"No aguanto este calor\",\n","    \"Qué hermoso día para pasear\",\n","    \"Detesto levantarme temprano\"\n","]\n","\n","# Vectorizamos las frases nuevas\n","X_prueba = np.array([vectorizar(frase, vocabulario) for frase in frases_prueba])\n","predicciones = [predecir(x) for x in X_prueba]\n","\n","# Mostramos los resultados\n","for frase, pred in zip(frases_prueba, predicciones):\n","    resultado = \"Positivo\" if pred == 1 else \"Negativo\"\n","    print(f\"Frase: '{frase}' => Sentimiento predicho: {resultado}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gysCXfMRW91z","executionInfo":{"status":"ok","timestamp":1747952539160,"user_tz":180,"elapsed":20,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"525c7549-a7c7-4f31-8020-6ef475ed8f80"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Frase: 'No aguanto este calor' => Sentimiento predicho: Negativo\n","Frase: 'Qué hermoso día para pasear' => Sentimiento predicho: Positivo\n","Frase: 'Detesto levantarme temprano' => Sentimiento predicho: Positivo\n"]}]},{"cell_type":"markdown","source":["##🧠 Reflexión final\n","###👉 ¿Qué aprendimos?\n","\n","* Cómo una neurona artificial puede aprender una tarea simple ajustando sus pesos.\n","\n","* Qué significa \"entrenar\" un modelo en la práctica.\n","\n","* Qué limitaciones tiene este enfoque (por ejemplo, no considera el orden de las palabras, sarcasmo, ambigüedad, etc.).\n","\n","En el proximo laboratorio, veremos cómo redes neuronales más complejas (con varias capas) pueden capturar patrones más sutiles y mejorar la predicción. 🚀"],"metadata":{"id":"HEWfDSlyXMVU"}}]}