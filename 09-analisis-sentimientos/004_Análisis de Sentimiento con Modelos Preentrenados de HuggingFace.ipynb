{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP/p1/qzWjfJcujheru76MT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Actividad Bonus: An치lisis de Sentimiento con Modelos Preentrenados de HuggingFace\n","##游꿢 Objetivo\n","En esta actividad vamos a utilizar un modelo de estado del arte ya entrenado para analizar el sentimiento de frases en espa침ol con apenas unas l칤neas de c칩digo, gracias a la librer칤a HuggingFace Transformers.\n","\n","Vamos a mostrar c칩mo es posible aprovechar el poder de los Transformers como BERT sin necesidad de entrenar redes neuronales desde cero."],"metadata":{"id":"7NextsCifGIB"}},{"cell_type":"markdown","source":["##游빓 1. Instalaci칩n de la librer칤a transformers\n","Si est치s en Google Colab, instal치 la librer칤a con el siguiente comando:"],"metadata":{"id":"8g7lq9VvfUan"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsZcO6fBfFSg"},"outputs":[],"source":["!pip install -q transformers"]},{"cell_type":"markdown","source":["##游뱅 2. Cargando un modelo preentrenado de HuggingFace\n","Usaremos el modelo BETO para espa침ol, ajustado espec칤ficamente para an치lisis de sentimiento:\n","* 游늷 finiteautomata/beto-sentiment-analysis"],"metadata":{"id":"AjY5dulRfaef"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Cargamos el pipeline de an치lisis de sentimientos con el modelo en espa침ol\n","clasificador = pipeline(\"sentiment-analysis\", model=\"finiteautomata/beto-sentiment-analysis\")"],"metadata":{"id":"zHvM7bpAfiZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##游빍 3. Evaluaci칩n de frases\n","Ahora vamos a probar el modelo con frases reales o inventadas, incluyendo expresiones t칤picas de Argentina."],"metadata":{"id":"sNG0MT9YflJ_"}},{"cell_type":"code","source":["frases = [\n","    \"Este lugar es espectacular, lo recomiendo totalmente\",\n","    \"Una decepci칩n total. No pienso volver\",\n","    \"M치s o menos... esperaba otra cosa\",\n","    \"춰Qu칠 buena onda la atenci칩n! Me encant칩\",\n","    \"Mala calidad, p칠simo servicio\",\n","    \"Zafa, pero nada especial\",\n","    \"Me sent칤 muy bien atendido\",\n","    \"Una estafa. Me arrepiento totalmente\",\n","    \"Todo excelente, 10 puntos\",\n","    \"Nunca m치s. Fue un desastre\"\n","]\n","\n","# Clasificamos cada frase\n","resultados = clasificador(frases)\n","\n","# Mostramos los resultados\n","for frase, resultado in zip(frases, resultados):\n","    print(f\"Frase: '{frase}' => {resultado['label']} ({resultado['score']:.2f})\")"],"metadata":{"id":"hw-GWqECfpxH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#游 Reflexi칩n final\n","##游녤 쯈u칠 aprendimos?\n","\n","* Que no es necesario entrenar desde cero para obtener buenos resultados en PLN.\n","\n","* Que existen modelos preentrenados en espa침ol que entienden texto coloquial.\n","\n","* C칩mo usar Transformers para tareas pr치cticas con apenas unas l칤neas de c칩digo.\n","\n","* Que el modelo BETO fue entrenado con gran cantidad de texto en espa침ol y entiende expresiones reales (춰incluso rioplatenses!)."],"metadata":{"id":"76Fz-HHJfpY3"}}]}