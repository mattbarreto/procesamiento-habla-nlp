{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vrNt9HrmSwhatyZi3loUOfPoxnPMKSEP","timestamp":1747170547894}],"authorship_tag":"ABX9TyNj+MBpEF6vlvcLe6zn7++P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Clasificacion de Letras Escritas a Mano con Redes Neuronales\n","\n","Comencemos cargando y preparando las herramientas que necesitamos:"],"metadata":{"id":"IVXv4eBz_ffC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bu5C46QeY0kF"},"outputs":[],"source":["print(\"Instalando librerías necesarias...\")\n","!pip install opencv-python-headless seaborn\n","print(\"Librerías instaladas.\")\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import cv2\n","import os\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"\\n¡Herramientas cargadas!\")"]},{"cell_type":"markdown","source":["## Paso 1: Cargar y Explorar los Datos de Letras Escritas (EMNIST)\n","\n","Vamos a cargar un dataset llamado EMNIST (Extended MNIST), que contiene imágenes de letras. Este conjunto de datos nos ayudará a entrenar nuestra red neuronal para que reconozca letras escritas a mano."],"metadata":{"id":"DwuUzcGT_2Pi"}},{"cell_type":"code","source":["print(\"\\nDescargando y cargando el dataset EMNIST/Letters. ¡Esto puede tardar unos minutos la primera vez!\")\n","datos, metadatos = tfds.load('emnist/letters', as_supervised=True, with_info=True)\n","print(\"Dataset EMNIST/Letters cargado.\")\n","\n","# Generamos una lista de nombres de las clases (letras)\n","nombres_clases = [chr(i + ord('a') - 1) for i in range(1, 27)]  # 'a' a 'z'\n","print(\"\\nNombres de las clases (letras):\", nombres_clases)"],"metadata":{"id":"X9jLpQoL__9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 2: Preprocesamiento de los Datos\n","\n","Las imágenes originales tienen valores de píxeles entre 0 y 255. Para trabajar con redes neuronales, es mejor normalizarlos a una escala de 0 a 1.\n","Además, ajustaremos las etiquetas de forma que comiencen desde 0."],"metadata":{"id":"Uwc7IpTsAJH-"}},{"cell_type":"code","source":["# Definimos una función simple para aplicar estos dos pasos:\n","def preprocesar_imagen(imagen, etiqueta):\n","  # 1. Normalizar píxeles: Convertir a decimal y dividir por 255.\n","  imagen = tf.cast(imagen, tf.float32) / 255.0\n","  # 2. Ajustar etiqueta: Restar 1 para empezar desde 0.\n","  etiqueta = etiqueta - 1\n","  return imagen, etiqueta # Devuelve la imagen y etiqueta procesadas.\n","\n","# Aplicamos esta función a todas las imágenes del dataset.\n","# Separamos en datos para 'entrenamiento' y datos para 'prueba'.\n","# .map(): Aplica nuestra función de preprocesamiento a cada elemento.\n","# .cache(): Almacena los resultados en memoria para acelerar el acceso futuro.\n","datos_entrenamiento = datos['train'].map(preprocesar_imagen).cache()\n","datos_pruebas = datos['test'].map(preprocesar_imagen).cache()\n","\n","print(\"\\n¡Datos preprocesados! Listos para ser utilizados por la red neuronal.\")"],"metadata":{"id":"oF8jD0LlANb0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 3: Visualización de Datos\n","\n","Antes de avanzar, visualicemos cómo se ven las letras en nuestros datos normalizados. Esto nos dará una mejor idea de lo que estamos trabajando."],"metadata":{"id":"ODj7SRCWAXdF"}},{"cell_type":"code","source":["# Extraemos un ejemplo del conjunto de entrenamiento.\n","for imagen, etiqueta in datos_entrenamiento.take(1):\n","  # Convertimos los datos a un formato que Matplotlib pueda dibujar.\n","  imagen_a_mostrar = imagen.numpy()\n","  etiqueta_numerica = etiqueta.numpy()\n","\n","# Creamos la visualización.\n","plt.figure()\n","# Mostramos la imagen. cmap=plt.cm.binary indica escala de grises.\n","# Accedemos al contenido de la imagen con [:, :, 0].\n","plt.imshow(imagen_a_mostrar[:, :, 0], cmap=plt.cm.binary)\n","# Añadimos un título descriptivo usando nuestra lista de nombres_clases.\n","plt.title(f\"Ejemplo de letra preprocesada: '{nombres_clases[etiqueta_numerica]}'\")\n","plt.colorbar() # Muestra la escala de valores (0 a 1).\n","plt.grid(False) # Ocultamos la cuadrícula para mayor claridad.\n","plt.show() # Mostramos el gráfico."],"metadata":{"id":"tzv1ifZrAYGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 4: Construir el Modelo de Red Neuronal\n","\n","Ahora que tenemos nuestros datos listos, es momento de construir nuestra red neuronal. Utilizaremos un modelo simple llamado Perceptrón Multicapa (MLP)."],"metadata":{"id":"HyVBsZzTAmJJ"}},{"cell_type":"code","source":["# Creamos un modelo secuencial (una pila de capas).\n","modelo = tf.keras.Sequential([\n","    # 1. Capa Flatten: Convierte la imagen 28x28 en un vector de 784.\n","    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n","\n","    # 2. Capas Ocultas (Dense): Con 64 neuronas cada una y activación 'relu'.\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","\n","    # 3. Capa de Salida (Dense): 26 neuronas (una por letra), activación 'softmax'.\n","    tf.keras.layers.Dense(len(nombres_clases), activation='softmax')\n","])\n","\n","# Compilamos el modelo, especificando cómo debe aprender:\n","modelo.compile(\n","    optimizer='adam', # Algoritmo para ajustar el modelo ('Adam' es eficiente y popular).\n","    loss='sparse_categorical_crossentropy', # Función para medir el error durante el entrenamiento.\n","    metrics=['accuracy'] # Métrica para evaluar el rendimiento (porcentaje de aciertos).\n",")\n","\n","print(\"\\n¡Modelo de Red Neuronal construido y compilado! Listo para el entrenamiento.\")\n","# Si quieren ver detalles técnicos de las capas (parámetros, etc.), pueden descomentar:\n","modelo.summary()"],"metadata":{"id":"OU1ya2DWAmwa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 5: Preparar los Datos para el Entrenamiento\n","\n","Para entrenar el modelo, necesitamos preparar nuestros datos en lotes eficientes.\n","También es común mezclar los datos para que el modelo no aprenda de un patrón en específico."],"metadata":{"id":"dJboQt_8Aut0"}},{"cell_type":"code","source":["TAMANO_LOTE = 32 # Número de imágenes que el modelo verá en cada paso de entrenamiento.\n","\n","# Obtenemos el número total de ejemplos de entrenamiento para la mezcla.\n","num_ejemplos_entrenamiento = metadatos.splits['train'].num_examples\n","\n","# Preparamos el dataset de entrenamiento:\n","# .shuffle(): Mezcla los datos aleatoriamente.\n","# .batch(): Agrupa los datos en lotes del tamaño especificado.\n","# .repeat(): Permite al proceso de entrenamiento iterar sobre los datos múltiples veces (épocas).\n","datos_entrenamiento = datos_entrenamiento.shuffle(num_ejemplos_entrenamiento).batch(TAMANO_LOTE).repeat()\n","\n","# Preparamos el dataset de pruebas: solo necesitamos agruparlo en lotes.\n","datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)\n","\n","print(f\"\\nDatos organizados en lotes de {TAMANO_LOTE} para un entrenamiento eficiente.\")"],"metadata":{"id":"9m3uIz5PAtH3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 6: ¡Entrenar el Modelo!\n","\n","Ahora llegó el momento de entrenar la red neuronal. Este proceso permitirá que el modelo aprenda a reconocer letras."],"metadata":{"id":"asvqxj6TA1iV"}},{"cell_type":"code","source":["# Definimos cuántas épocas (pasadas completas) de entrenamiento realizaremos.\n","# Entre 5 y 10 suele ser suficiente para ver un aprendizaje significativo en este problema.\n","EPOCAS = 15\n","\n","print(f\"\\nIniciando el entrenamiento por {EPOCAS} épocas...\")\n","print(\"Observen cómo la 'accuracy' (precisión) debería mejorar con cada época.\")\n","\n","# Ejecutamos el entrenamiento con model.fit()\n","historial = modelo.fit(\n","    datos_entrenamiento, # Los datos preprocesados para entrenar.\n","    epochs=EPOCAS, # El número de pasadas completas.\n","    # steps_per_epoch indica cuántos lotes procesar por época para cubrir aprox. todo el dataset.\n","    steps_per_epoch=math.ceil(num_ejemplos_entrenamiento / TAMANO_LOTE)\n","    # Opcional: Podemos añadir 'validation_data=datos_pruebas' para ver el rendimiento\n","    # en los datos de prueba después de cada época, lo cual es muy informativo.\n",")\n","\n","print(\"\\n¡Entrenamiento completado! 🎉 El modelo ha finalizado su proceso de aprendizaje.\")"],"metadata":{"id":"nIXbkPwRA2RO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 7: Evaluar el Modelo\n","\n","Una vez que el modelo ha sido entrenado, es importante evaluarlo con datos que no ha visto antes. Esto nos dirá qué tan bien está funcionando."],"metadata":{"id":"BgOzSJvVBA3i"}},{"cell_type":"code","source":["print(\"\\nEvaluando el rendimiento del modelo con datos nuevos (conjunto de prueba)...\")\n","# Usamos model.evaluate() para calcular la pérdida y precisión en el conjunto de prueba.\n","loss_prueba, accuracy_prueba = modelo.evaluate(datos_pruebas)\n","\n","print(f\"\\nResultados de la Evaluación:\")\n","print(f\"  - Pérdida (Loss) en prueba: {loss_prueba:.4f}\")\n","print(f\"  - Precisión (Accuracy) en prueba: {accuracy_prueba:.4f} (Equivalente a {accuracy_prueba*100:.2f}%)\")\n","\n","if accuracy_prueba > 0.80:\n","    print(\"\\n¡Excelente resultado! Una precisión superior al 80% en datos no vistos indica un buen aprendizaje y generalización. 👍\")\n","elif accuracy_prueba > 0.65:\n","    print(\"\\n¡Buen resultado! Superar el 65% muestra que el modelo ha captado patrones importantes. ¡Un sólido punto de partida! 😊\")\n","else:\n","    print(\"\\nEl modelo ha aprendido, pero hay margen de mejora. ¡Parte del proceso es experimentar para optimizar! 💪\")"],"metadata":{"id":"8J_B6KIFBBN_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Paso 7.5: Visualizando la Curva de Aprendizaje 📈\n","\n","El objeto historial que guardamos durante el entrenamiento (modelo.fit) contiene información valiosa sobre cómo evolucionaron las métricas (como la precisión y la pérdida) en cada época. Graficar esto nos da una visión clara del proceso de aprendizaje."],"metadata":{"id":"9YPXQ_NFbcYn"}},{"cell_type":"code","source":["print(\"\\n--- Visualizando el Proceso de Aprendizaje ---\")\n","\n","# El objeto 'historial' tiene un diccionario llamado 'history' con las métricas por época.\n","# Las claves típicas son 'loss', 'accuracy'. Si usamos datos de validación,\n","# también tendríamos 'val_loss' y 'val_accuracy'.\n","\n","# Extraemos las métricas del historial.\n","historial_dict = historial.history\n","epocas_rango = range(1, EPOCAS + 1) # Creamos una secuencia de números para el eje X (las épocas)\n","\n","# Graficar la Precisión (Accuracy)\n","plt.figure(figsize=(12, 5)) # Creamos una figura para los gráficos\n","\n","plt.subplot(1, 2, 1) # Definimos el primer subgráfico (1 fila, 2 columnas, posición 1)\n","plt.plot(epocas_rango, historial_dict['accuracy'], 'bo-', label='Precisión Entrenamiento') # 'bo-' = puntos azules conectados\n","# Si hubiéramos usado datos de validación en fit(), podríamos añadir la curva de validación:\n","# if 'val_accuracy' in historial_dict:\n","#    plt.plot(epocas_rango, historial_dict['val_accuracy'], 'ro-', label='Precisión Validación')\n","plt.title('Precisión durante el Entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Precisión (Accuracy)')\n","plt.xticks(epocas_rango) # Asegura que se muestren todas las épocas en el eje X\n","plt.legend() # Muestra la leyenda ('Precisión Entrenamiento', etc.)\n","plt.grid(True) # Añade una grilla para facilitar la lectura\n","\n","# Graficar la Pérdida (Loss)\n","plt.subplot(1, 2, 2) # Definimos el segundo subgráfico (1 fila, 2 columnas, posición 2)\n","plt.plot(epocas_rango, historial_dict['loss'], 'gs-', label='Pérdida Entrenamiento') # 'gs-' = cuadrados verdes conectados\n","# Si hubiéramos usado datos de validación en fit():\n","# if 'val_loss' in historial_dict:\n","#    plt.plot(epocas_rango, historial_dict['val_loss'], 'rs-', label='Pérdida Validación')\n","plt.title('Pérdida durante el Entrenamiento')\n","plt.xlabel('Épocas')\n","plt.ylabel('Pérdida (Loss)')\n","plt.xticks(epocas_rango)\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout() # Ajusta el espaciado entre los subgráficos\n","plt.show()\n","\n","print(\"\\nAnálisis de las Curvas:\")\n","print(\"- Idealmente, la Precisión de Entrenamiento debe subir y la Pérdida debe bajar.\")\n","# Si tuviéramos curvas de validación:\n","# print(\"- Si la Precisión de Validación se estanca o baja mientras la de Entrenamiento sigue subiendo,\")\n","# print(\"  podría ser un signo de 'sobreajuste' (overfitting): el modelo memoriza los datos de entrenamiento\")\n","# print(\"  pero no generaliza bien a datos nuevos.\")\n","# print(\"- De forma similar, si la Pérdida de Validación empieza a subir, también indica posible sobreajuste.\")\n","print(\"- Estas curvas nos ayudan a decidir si necesitamos más/menos épocas, regularización, etc.\")"],"metadata":{"id":"24nSaTl0bQvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 8: Visualizar Predicciones\n","\n","Ahora viene la parte divertida y visual. Vamos a ver qué predice la red para algunas imágenes de prueba y si acertó o no. ¡Vamos a usar unas funciones para graficar esto de forma clara!"],"metadata":{"id":"q1TzYz9UBiKz"}},{"cell_type":"code","source":["# Tomamos un lote de imágenes y etiquetas del conjunto de prueba.\n","for imagenes_lote_prueba, etiquetas_lote_prueba in datos_pruebas.take(1):\n","    imagenes_a_predecir = imagenes_lote_prueba.numpy()\n","    etiquetas_reales = etiquetas_lote_prueba.numpy()\n","    # Pedimos al modelo que genere las predicciones (probabilidades para cada letra).\n","    predicciones_probabilidades = modelo.predict(imagenes_a_predecir)\n","    break # Solo necesitamos un lote para visualizar.\n","\n","# Función auxiliar para graficar una imagen con su predicción.\n","def graficar_prediccion(indice, probabilidades, etiquetas_verdaderas, imagenes):\n","    probabilidad_predicha = probabilidades[indice]\n","    etiqueta_verdadera = etiquetas_verdaderas[indice]\n","    imagen = imagenes[indice]\n","\n","    plt.grid(False); plt.xticks([]); plt.yticks([]) # Limpiamos ejes y grilla\n","    plt.imshow(imagen[:, :, 0], cmap=plt.cm.binary) # Mostramos imagen\n","\n","    # Encontramos la letra con la mayor probabilidad asignada por el modelo.\n","    indice_predicho = np.argmax(probabilidad_predicha)\n","    letra_predicha = nombres_clases[indice_predicho]\n","    letra_real = nombres_clases[etiqueta_verdadera]\n","\n","    # Asignamos color según si la predicción fue correcta o no.\n","    color = 'blue' if indice_predicho == etiqueta_verdadera else 'red'\n","\n","    # Añadimos etiqueta con la predicción, confianza y valor real.\n","    plt.xlabel(f\"Predijo: {letra_predicha} ({100*np.max(probabilidad_predicha):.0f}%)\\nReal: {letra_real}\", color=color)\n","\n","# Mostramos un conjunto de predicciones.\n","num_filas = 3\n","num_columnas = 5\n","num_imagenes_a_mostrar = num_filas * num_columnas\n","\n","plt.figure(figsize=(2 * num_columnas + 1, 2 * num_filas + 2)) # Ajustamos tamaño figura\n","plt.suptitle(\"Ejemplos de Predicciones del Modelo (Azul=Correcto, Rojo=Incorrecto)\", fontsize=14)\n","for i in range(num_imagenes_a_mostrar):\n","    plt.subplot(num_filas, num_columnas, i + 1) # Creamos espacio para cada imagen\n","    graficar_prediccion(i, predicciones_probabilidades, etiquetas_reales, imagenes_a_predecir)\n","plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ajustamos espaciado\n","plt.show()"],"metadata":{"id":"tbpfHdsJBizd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 9: Analizando Errores con la Matriz de Confusión\n","\n","Para entender mejor cómo se comporta nuestra red, utilizaremos una Matriz de Confusión. Esto nos permitirá visualizar dónde se cometen errores."],"metadata":{"id":"S0B7lRi7CXg8"}},{"cell_type":"code","source":["print(\"\\nGenerando la Matriz de Confusión para analizar los errores...\")\n","print(\"(Requiere procesar todas las predicciones del conjunto de prueba, puede tardar unos instantes)\")\n","\n","# Necesitamos obtener las predicciones para TODO el conjunto de prueba.\n","indices_predichos_todos = []\n","etiquetas_reales_todas = []\n","\n","# Iteramos sobre todos los lotes del conjunto de prueba.\n","for imagenes_lote, etiquetas_lote in datos_pruebas:\n","    # Obtenemos las predicciones de probabilidad.\n","    probs_lote = modelo.predict(imagenes_lote, verbose=0)\n","    # Obtenemos el índice de la clase más probable para cada imagen.\n","    indices_predichos_lote = np.argmax(probs_lote, axis=1)\n","    # Acumulamos los resultados.\n","    indices_predichos_todos.extend(indices_predichos_lote)\n","    etiquetas_reales_todas.extend(etiquetas_lote.numpy())\n","\n","# Convertimos a arrays de NumPy para la función de la matriz.\n","indices_predichos_todos = np.array(indices_predichos_todos)\n","etiquetas_reales_todas = np.array(etiquetas_reales_todas)\n","\n","# Calculamos la matriz de confusión.\n","matriz_conf = confusion_matrix(etiquetas_reales_todas, indices_predichos_todos)\n","\n","# Visualizamos la matriz usando Seaborn para una mejor presentación.\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(matriz_conf, annot=False, cmap='Blues', fmt='d', # annot=False si hay muchas clases\n","            xticklabels=nombres_clases, yticklabels=nombres_clases)\n","plt.xlabel('Etiqueta Predicha por el Modelo', fontsize=12)\n","plt.ylabel('Etiqueta Real', fontsize=12)\n","plt.title('Matriz de Confusión: Rendimiento por Clase', fontsize=14)\n","plt.show()\n","\n","print(\"\\nInterpretación de la Matriz de Confusión:\")\n","print(\"- Cada fila representa las instancias de una letra REAL.\")\n","print(\"- Cada columna representa las predicciones hechas por el modelo para una letra.\")\n","print(\"- La DIAGONAL PRINCIPAL (de arriba-izquierda a abajo-derecha) muestra los ACIERTOS.\")\n","print(\"  (Casos donde la letra real 'X' fue clasificada como 'X'). Idealmente, esta diagonal es intensa (oscura).\")\n","print(\"- Los valores FUERA de la diagonal representan ERRORES (confusiones).\")\n","print(\"  (Por ejemplo, un valor en la fila 'i', columna 'l' indica cuántas veces una 'i' real fue clasificada erróneamente como 'l').\")"],"metadata":{"id":"K8F02JdTCYNt"},"execution_count":null,"outputs":[]}]}