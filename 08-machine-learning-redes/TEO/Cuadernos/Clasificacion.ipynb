{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vrNt9HrmSwhatyZi3loUOfPoxnPMKSEP","timestamp":1747170547894}],"authorship_tag":"ABX9TyNj+MBpEF6vlvcLe6zn7++P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Clasificacion de Letras Escritas a Mano con Redes Neuronales\n","\n","Comencemos cargando y preparando las herramientas que necesitamos:"],"metadata":{"id":"IVXv4eBz_ffC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bu5C46QeY0kF"},"outputs":[],"source":["print(\"Instalando librer铆as necesarias...\")\n","!pip install opencv-python-headless seaborn\n","print(\"Librer铆as instaladas.\")\n","\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import cv2\n","import os\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","print(\"\\n隆Herramientas cargadas!\")"]},{"cell_type":"markdown","source":["## Paso 1: Cargar y Explorar los Datos de Letras Escritas (EMNIST)\n","\n","Vamos a cargar un dataset llamado EMNIST (Extended MNIST), que contiene im谩genes de letras. Este conjunto de datos nos ayudar谩 a entrenar nuestra red neuronal para que reconozca letras escritas a mano."],"metadata":{"id":"DwuUzcGT_2Pi"}},{"cell_type":"code","source":["print(\"\\nDescargando y cargando el dataset EMNIST/Letters. 隆Esto puede tardar unos minutos la primera vez!\")\n","datos, metadatos = tfds.load('emnist/letters', as_supervised=True, with_info=True)\n","print(\"Dataset EMNIST/Letters cargado.\")\n","\n","# Generamos una lista de nombres de las clases (letras)\n","nombres_clases = [chr(i + ord('a') - 1) for i in range(1, 27)]  # 'a' a 'z'\n","print(\"\\nNombres de las clases (letras):\", nombres_clases)"],"metadata":{"id":"X9jLpQoL__9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 2: Preprocesamiento de los Datos\n","\n","Las im谩genes originales tienen valores de p铆xeles entre 0 y 255. Para trabajar con redes neuronales, es mejor normalizarlos a una escala de 0 a 1.\n","Adem谩s, ajustaremos las etiquetas de forma que comiencen desde 0."],"metadata":{"id":"Uwc7IpTsAJH-"}},{"cell_type":"code","source":["# Definimos una funci贸n simple para aplicar estos dos pasos:\n","def preprocesar_imagen(imagen, etiqueta):\n","  # 1. Normalizar p铆xeles: Convertir a decimal y dividir por 255.\n","  imagen = tf.cast(imagen, tf.float32) / 255.0\n","  # 2. Ajustar etiqueta: Restar 1 para empezar desde 0.\n","  etiqueta = etiqueta - 1\n","  return imagen, etiqueta # Devuelve la imagen y etiqueta procesadas.\n","\n","# Aplicamos esta funci贸n a todas las im谩genes del dataset.\n","# Separamos en datos para 'entrenamiento' y datos para 'prueba'.\n","# .map(): Aplica nuestra funci贸n de preprocesamiento a cada elemento.\n","# .cache(): Almacena los resultados en memoria para acelerar el acceso futuro.\n","datos_entrenamiento = datos['train'].map(preprocesar_imagen).cache()\n","datos_pruebas = datos['test'].map(preprocesar_imagen).cache()\n","\n","print(\"\\n隆Datos preprocesados! Listos para ser utilizados por la red neuronal.\")"],"metadata":{"id":"oF8jD0LlANb0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 3: Visualizaci贸n de Datos\n","\n","Antes de avanzar, visualicemos c贸mo se ven las letras en nuestros datos normalizados. Esto nos dar谩 una mejor idea de lo que estamos trabajando."],"metadata":{"id":"ODj7SRCWAXdF"}},{"cell_type":"code","source":["# Extraemos un ejemplo del conjunto de entrenamiento.\n","for imagen, etiqueta in datos_entrenamiento.take(1):\n","  # Convertimos los datos a un formato que Matplotlib pueda dibujar.\n","  imagen_a_mostrar = imagen.numpy()\n","  etiqueta_numerica = etiqueta.numpy()\n","\n","# Creamos la visualizaci贸n.\n","plt.figure()\n","# Mostramos la imagen. cmap=plt.cm.binary indica escala de grises.\n","# Accedemos al contenido de la imagen con [:, :, 0].\n","plt.imshow(imagen_a_mostrar[:, :, 0], cmap=plt.cm.binary)\n","# A帽adimos un t铆tulo descriptivo usando nuestra lista de nombres_clases.\n","plt.title(f\"Ejemplo de letra preprocesada: '{nombres_clases[etiqueta_numerica]}'\")\n","plt.colorbar() # Muestra la escala de valores (0 a 1).\n","plt.grid(False) # Ocultamos la cuadr铆cula para mayor claridad.\n","plt.show() # Mostramos el gr谩fico."],"metadata":{"id":"tzv1ifZrAYGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 4: Construir el Modelo de Red Neuronal\n","\n","Ahora que tenemos nuestros datos listos, es momento de construir nuestra red neuronal. Utilizaremos un modelo simple llamado Perceptr贸n Multicapa (MLP)."],"metadata":{"id":"HyVBsZzTAmJJ"}},{"cell_type":"code","source":["# Creamos un modelo secuencial (una pila de capas).\n","modelo = tf.keras.Sequential([\n","    # 1. Capa Flatten: Convierte la imagen 28x28 en un vector de 784.\n","    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n","\n","    # 2. Capas Ocultas (Dense): Con 64 neuronas cada una y activaci贸n 'relu'.\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","\n","    # 3. Capa de Salida (Dense): 26 neuronas (una por letra), activaci贸n 'softmax'.\n","    tf.keras.layers.Dense(len(nombres_clases), activation='softmax')\n","])\n","\n","# Compilamos el modelo, especificando c贸mo debe aprender:\n","modelo.compile(\n","    optimizer='adam', # Algoritmo para ajustar el modelo ('Adam' es eficiente y popular).\n","    loss='sparse_categorical_crossentropy', # Funci贸n para medir el error durante el entrenamiento.\n","    metrics=['accuracy'] # M茅trica para evaluar el rendimiento (porcentaje de aciertos).\n",")\n","\n","print(\"\\n隆Modelo de Red Neuronal construido y compilado! Listo para el entrenamiento.\")\n","# Si quieren ver detalles t茅cnicos de las capas (par谩metros, etc.), pueden descomentar:\n","modelo.summary()"],"metadata":{"id":"OU1ya2DWAmwa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 5: Preparar los Datos para el Entrenamiento\n","\n","Para entrenar el modelo, necesitamos preparar nuestros datos en lotes eficientes.\n","Tambi茅n es com煤n mezclar los datos para que el modelo no aprenda de un patr贸n en espec铆fico."],"metadata":{"id":"dJboQt_8Aut0"}},{"cell_type":"code","source":["TAMANO_LOTE = 32 # N煤mero de im谩genes que el modelo ver谩 en cada paso de entrenamiento.\n","\n","# Obtenemos el n煤mero total de ejemplos de entrenamiento para la mezcla.\n","num_ejemplos_entrenamiento = metadatos.splits['train'].num_examples\n","\n","# Preparamos el dataset de entrenamiento:\n","# .shuffle(): Mezcla los datos aleatoriamente.\n","# .batch(): Agrupa los datos en lotes del tama帽o especificado.\n","# .repeat(): Permite al proceso de entrenamiento iterar sobre los datos m煤ltiples veces (茅pocas).\n","datos_entrenamiento = datos_entrenamiento.shuffle(num_ejemplos_entrenamiento).batch(TAMANO_LOTE).repeat()\n","\n","# Preparamos el dataset de pruebas: solo necesitamos agruparlo en lotes.\n","datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)\n","\n","print(f\"\\nDatos organizados en lotes de {TAMANO_LOTE} para un entrenamiento eficiente.\")"],"metadata":{"id":"9m3uIz5PAtH3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 6: 隆Entrenar el Modelo!\n","\n","Ahora lleg贸 el momento de entrenar la red neuronal. Este proceso permitir谩 que el modelo aprenda a reconocer letras."],"metadata":{"id":"asvqxj6TA1iV"}},{"cell_type":"code","source":["# Definimos cu谩ntas 茅pocas (pasadas completas) de entrenamiento realizaremos.\n","# Entre 5 y 10 suele ser suficiente para ver un aprendizaje significativo en este problema.\n","EPOCAS = 15\n","\n","print(f\"\\nIniciando el entrenamiento por {EPOCAS} 茅pocas...\")\n","print(\"Observen c贸mo la 'accuracy' (precisi贸n) deber铆a mejorar con cada 茅poca.\")\n","\n","# Ejecutamos el entrenamiento con model.fit()\n","historial = modelo.fit(\n","    datos_entrenamiento, # Los datos preprocesados para entrenar.\n","    epochs=EPOCAS, # El n煤mero de pasadas completas.\n","    # steps_per_epoch indica cu谩ntos lotes procesar por 茅poca para cubrir aprox. todo el dataset.\n","    steps_per_epoch=math.ceil(num_ejemplos_entrenamiento / TAMANO_LOTE)\n","    # Opcional: Podemos a帽adir 'validation_data=datos_pruebas' para ver el rendimiento\n","    # en los datos de prueba despu茅s de cada 茅poca, lo cual es muy informativo.\n",")\n","\n","print(\"\\n隆Entrenamiento completado!  El modelo ha finalizado su proceso de aprendizaje.\")"],"metadata":{"id":"nIXbkPwRA2RO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 7: Evaluar el Modelo\n","\n","Una vez que el modelo ha sido entrenado, es importante evaluarlo con datos que no ha visto antes. Esto nos dir谩 qu茅 tan bien est谩 funcionando."],"metadata":{"id":"BgOzSJvVBA3i"}},{"cell_type":"code","source":["print(\"\\nEvaluando el rendimiento del modelo con datos nuevos (conjunto de prueba)...\")\n","# Usamos model.evaluate() para calcular la p茅rdida y precisi贸n en el conjunto de prueba.\n","loss_prueba, accuracy_prueba = modelo.evaluate(datos_pruebas)\n","\n","print(f\"\\nResultados de la Evaluaci贸n:\")\n","print(f\"  - P茅rdida (Loss) en prueba: {loss_prueba:.4f}\")\n","print(f\"  - Precisi贸n (Accuracy) en prueba: {accuracy_prueba:.4f} (Equivalente a {accuracy_prueba*100:.2f}%)\")\n","\n","if accuracy_prueba > 0.80:\n","    print(\"\\n隆Excelente resultado! Una precisi贸n superior al 80% en datos no vistos indica un buen aprendizaje y generalizaci贸n. \")\n","elif accuracy_prueba > 0.65:\n","    print(\"\\n隆Buen resultado! Superar el 65% muestra que el modelo ha captado patrones importantes. 隆Un s贸lido punto de partida! \")\n","else:\n","    print(\"\\nEl modelo ha aprendido, pero hay margen de mejora. 隆Parte del proceso es experimentar para optimizar! \")"],"metadata":{"id":"8J_B6KIFBBN_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Paso 7.5: Visualizando la Curva de Aprendizaje \n","\n","El objeto historial que guardamos durante el entrenamiento (modelo.fit) contiene informaci贸n valiosa sobre c贸mo evolucionaron las m茅tricas (como la precisi贸n y la p茅rdida) en cada 茅poca. Graficar esto nos da una visi贸n clara del proceso de aprendizaje."],"metadata":{"id":"9YPXQ_NFbcYn"}},{"cell_type":"code","source":["print(\"\\n--- Visualizando el Proceso de Aprendizaje ---\")\n","\n","# El objeto 'historial' tiene un diccionario llamado 'history' con las m茅tricas por 茅poca.\n","# Las claves t铆picas son 'loss', 'accuracy'. Si usamos datos de validaci贸n,\n","# tambi茅n tendr铆amos 'val_loss' y 'val_accuracy'.\n","\n","# Extraemos las m茅tricas del historial.\n","historial_dict = historial.history\n","epocas_rango = range(1, EPOCAS + 1) # Creamos una secuencia de n煤meros para el eje X (las 茅pocas)\n","\n","# Graficar la Precisi贸n (Accuracy)\n","plt.figure(figsize=(12, 5)) # Creamos una figura para los gr谩ficos\n","\n","plt.subplot(1, 2, 1) # Definimos el primer subgr谩fico (1 fila, 2 columnas, posici贸n 1)\n","plt.plot(epocas_rango, historial_dict['accuracy'], 'bo-', label='Precisi贸n Entrenamiento') # 'bo-' = puntos azules conectados\n","# Si hubi茅ramos usado datos de validaci贸n en fit(), podr铆amos a帽adir la curva de validaci贸n:\n","# if 'val_accuracy' in historial_dict:\n","#    plt.plot(epocas_rango, historial_dict['val_accuracy'], 'ro-', label='Precisi贸n Validaci贸n')\n","plt.title('Precisi贸n durante el Entrenamiento')\n","plt.xlabel('pocas')\n","plt.ylabel('Precisi贸n (Accuracy)')\n","plt.xticks(epocas_rango) # Asegura que se muestren todas las 茅pocas en el eje X\n","plt.legend() # Muestra la leyenda ('Precisi贸n Entrenamiento', etc.)\n","plt.grid(True) # A帽ade una grilla para facilitar la lectura\n","\n","# Graficar la P茅rdida (Loss)\n","plt.subplot(1, 2, 2) # Definimos el segundo subgr谩fico (1 fila, 2 columnas, posici贸n 2)\n","plt.plot(epocas_rango, historial_dict['loss'], 'gs-', label='P茅rdida Entrenamiento') # 'gs-' = cuadrados verdes conectados\n","# Si hubi茅ramos usado datos de validaci贸n en fit():\n","# if 'val_loss' in historial_dict:\n","#    plt.plot(epocas_rango, historial_dict['val_loss'], 'rs-', label='P茅rdida Validaci贸n')\n","plt.title('P茅rdida durante el Entrenamiento')\n","plt.xlabel('pocas')\n","plt.ylabel('P茅rdida (Loss)')\n","plt.xticks(epocas_rango)\n","plt.legend()\n","plt.grid(True)\n","\n","plt.tight_layout() # Ajusta el espaciado entre los subgr谩ficos\n","plt.show()\n","\n","print(\"\\nAn谩lisis de las Curvas:\")\n","print(\"- Idealmente, la Precisi贸n de Entrenamiento debe subir y la P茅rdida debe bajar.\")\n","# Si tuvi茅ramos curvas de validaci贸n:\n","# print(\"- Si la Precisi贸n de Validaci贸n se estanca o baja mientras la de Entrenamiento sigue subiendo,\")\n","# print(\"  podr铆a ser un signo de 'sobreajuste' (overfitting): el modelo memoriza los datos de entrenamiento\")\n","# print(\"  pero no generaliza bien a datos nuevos.\")\n","# print(\"- De forma similar, si la P茅rdida de Validaci贸n empieza a subir, tambi茅n indica posible sobreajuste.\")\n","print(\"- Estas curvas nos ayudan a decidir si necesitamos m谩s/menos 茅pocas, regularizaci贸n, etc.\")"],"metadata":{"id":"24nSaTl0bQvj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 8: Visualizar Predicciones\n","\n","Ahora viene la parte divertida y visual. Vamos a ver qu茅 predice la red para algunas im谩genes de prueba y si acert贸 o no. 隆Vamos a usar unas funciones para graficar esto de forma clara!"],"metadata":{"id":"q1TzYz9UBiKz"}},{"cell_type":"code","source":["# Tomamos un lote de im谩genes y etiquetas del conjunto de prueba.\n","for imagenes_lote_prueba, etiquetas_lote_prueba in datos_pruebas.take(1):\n","    imagenes_a_predecir = imagenes_lote_prueba.numpy()\n","    etiquetas_reales = etiquetas_lote_prueba.numpy()\n","    # Pedimos al modelo que genere las predicciones (probabilidades para cada letra).\n","    predicciones_probabilidades = modelo.predict(imagenes_a_predecir)\n","    break # Solo necesitamos un lote para visualizar.\n","\n","# Funci贸n auxiliar para graficar una imagen con su predicci贸n.\n","def graficar_prediccion(indice, probabilidades, etiquetas_verdaderas, imagenes):\n","    probabilidad_predicha = probabilidades[indice]\n","    etiqueta_verdadera = etiquetas_verdaderas[indice]\n","    imagen = imagenes[indice]\n","\n","    plt.grid(False); plt.xticks([]); plt.yticks([]) # Limpiamos ejes y grilla\n","    plt.imshow(imagen[:, :, 0], cmap=plt.cm.binary) # Mostramos imagen\n","\n","    # Encontramos la letra con la mayor probabilidad asignada por el modelo.\n","    indice_predicho = np.argmax(probabilidad_predicha)\n","    letra_predicha = nombres_clases[indice_predicho]\n","    letra_real = nombres_clases[etiqueta_verdadera]\n","\n","    # Asignamos color seg煤n si la predicci贸n fue correcta o no.\n","    color = 'blue' if indice_predicho == etiqueta_verdadera else 'red'\n","\n","    # A帽adimos etiqueta con la predicci贸n, confianza y valor real.\n","    plt.xlabel(f\"Predijo: {letra_predicha} ({100*np.max(probabilidad_predicha):.0f}%)\\nReal: {letra_real}\", color=color)\n","\n","# Mostramos un conjunto de predicciones.\n","num_filas = 3\n","num_columnas = 5\n","num_imagenes_a_mostrar = num_filas * num_columnas\n","\n","plt.figure(figsize=(2 * num_columnas + 1, 2 * num_filas + 2)) # Ajustamos tama帽o figura\n","plt.suptitle(\"Ejemplos de Predicciones del Modelo (Azul=Correcto, Rojo=Incorrecto)\", fontsize=14)\n","for i in range(num_imagenes_a_mostrar):\n","    plt.subplot(num_filas, num_columnas, i + 1) # Creamos espacio para cada imagen\n","    graficar_prediccion(i, predicciones_probabilidades, etiquetas_reales, imagenes_a_predecir)\n","plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ajustamos espaciado\n","plt.show()"],"metadata":{"id":"tbpfHdsJBizd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Paso 9: Analizando Errores con la Matriz de Confusi贸n\n","\n","Para entender mejor c贸mo se comporta nuestra red, utilizaremos una Matriz de Confusi贸n. Esto nos permitir谩 visualizar d贸nde se cometen errores."],"metadata":{"id":"S0B7lRi7CXg8"}},{"cell_type":"code","source":["print(\"\\nGenerando la Matriz de Confusi贸n para analizar los errores...\")\n","print(\"(Requiere procesar todas las predicciones del conjunto de prueba, puede tardar unos instantes)\")\n","\n","# Necesitamos obtener las predicciones para TODO el conjunto de prueba.\n","indices_predichos_todos = []\n","etiquetas_reales_todas = []\n","\n","# Iteramos sobre todos los lotes del conjunto de prueba.\n","for imagenes_lote, etiquetas_lote in datos_pruebas:\n","    # Obtenemos las predicciones de probabilidad.\n","    probs_lote = modelo.predict(imagenes_lote, verbose=0)\n","    # Obtenemos el 铆ndice de la clase m谩s probable para cada imagen.\n","    indices_predichos_lote = np.argmax(probs_lote, axis=1)\n","    # Acumulamos los resultados.\n","    indices_predichos_todos.extend(indices_predichos_lote)\n","    etiquetas_reales_todas.extend(etiquetas_lote.numpy())\n","\n","# Convertimos a arrays de NumPy para la funci贸n de la matriz.\n","indices_predichos_todos = np.array(indices_predichos_todos)\n","etiquetas_reales_todas = np.array(etiquetas_reales_todas)\n","\n","# Calculamos la matriz de confusi贸n.\n","matriz_conf = confusion_matrix(etiquetas_reales_todas, indices_predichos_todos)\n","\n","# Visualizamos la matriz usando Seaborn para una mejor presentaci贸n.\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(matriz_conf, annot=False, cmap='Blues', fmt='d', # annot=False si hay muchas clases\n","            xticklabels=nombres_clases, yticklabels=nombres_clases)\n","plt.xlabel('Etiqueta Predicha por el Modelo', fontsize=12)\n","plt.ylabel('Etiqueta Real', fontsize=12)\n","plt.title('Matriz de Confusi贸n: Rendimiento por Clase', fontsize=14)\n","plt.show()\n","\n","print(\"\\nInterpretaci贸n de la Matriz de Confusi贸n:\")\n","print(\"- Cada fila representa las instancias de una letra REAL.\")\n","print(\"- Cada columna representa las predicciones hechas por el modelo para una letra.\")\n","print(\"- La DIAGONAL PRINCIPAL (de arriba-izquierda a abajo-derecha) muestra los ACIERTOS.\")\n","print(\"  (Casos donde la letra real 'X' fue clasificada como 'X'). Idealmente, esta diagonal es intensa (oscura).\")\n","print(\"- Los valores FUERA de la diagonal representan ERRORES (confusiones).\")\n","print(\"  (Por ejemplo, un valor en la fila 'i', columna 'l' indica cu谩ntas veces una 'i' real fue clasificada err贸neamente como 'l').\")"],"metadata":{"id":"K8F02JdTCYNt"},"execution_count":null,"outputs":[]}]}