{"cells":[{"cell_type":"markdown","metadata":{"id":"11uLD9O6q0de"},"source":["# Aplicaciones de Transformers en Procesamiento de Lenguaje Natural\n","\n","Este cuaderno explora distintas aplicaciones de los modelos Transformers en tareas de procesamiento de lenguaje natural (PLN), utilizando ejemplos prácticos y explicaciones teóricas.\n","\n","---\n","\n","## ¿Qué es la arquitectura Transformer?\n","\n","La **arquitectura Transformer** es un tipo de red neuronal propuesta por Vaswani et al. en 2017. Su principal innovación es el mecanismo de *atención*, que permite al modelo enfocarse en diferentes partes de la entrada para procesar información contextual de manera eficiente. Los Transformers reemplazaron a modelos anteriores como LSTM y GRU en muchas tareas de PLN debido a su capacidad para manejar secuencias largas y aprender dependencias complejas.\n","\n","---\n","\n","## ¿Qué es la librería Transformers de Hugging Face?\n","\n","La **librería Transformers de Hugging Face** es una biblioteca de Python que proporciona implementaciones preentrenadas de modelos basados en la arquitectura Transformer (como BERT, GPT, T5, etc.) para tareas de PLN. Permite cargar modelos fácilmente y utilizarlos en tareas como clasificación, traducción, resumen, etc., sin necesidad de entrenarlos desde cero. Podes explorar los modelos disponibles en la [página de modelos de Hugging Face](https://huggingface.co/models).\n","\n","---\n","\n","## ¿Qué es un pipeline en Hugging Face?\n","\n","Un **pipeline** en Hugging Face es una interfaz de alto nivel que simplifica el uso de modelos preentrenados para tareas específicas. Permite ejecutar tareas como clasificación de texto, reconocimiento de entidades, traducción, etc., con solo unas pocas líneas de código, ocultando detalles complejos de preprocesamiento y postprocesamiento.\n"],"id":"11uLD9O6q0de"},{"cell_type":"markdown","metadata":{"id":"pGi_AA0Cq0dh"},"source":["## 1. Definir el texto de ejemplo\n","\n","A continuación, se presenta un texto de ejemplo que será utilizado en las distintas aplicaciones de modelos Transformers. Este texto simula una queja de un cliente sobre un pedido equivocado, lo que nos permitirá explorar tareas como clasificación, reconocimiento de entidades, respuesta a preguntas, resumen, traducción y generación de texto."],"id":"pGi_AA0Cq0dh"},{"cell_type":"code","metadata":{"id":"c5qDBq2Wq0di"},"source":["texto = \"\"\"Querido MercadoLibre, la semana pasada pedí una figura de acción de Optimus Prime desde su tienda online.\n","Para mi sorpresa, cuando abrí el paquete, descubrí horrorizado que me habían enviado una figura de Megatron.\n","Como fan de los Autobots, espero que entiendan mi decepción. Solicito un cambio urgente del producto.\"\"\""],"id":"c5qDBq2Wq0di","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a12gU1Xeq0di"},"source":["## 2. Clasificación de texto con Transformers\n","\n","La **clasificación de texto** es una tarea fundamental en PLN que consiste en asignar una o varias etiquetas a un texto, como por ejemplo identificar el sentimiento (positivo, negativo, neutro) o la intención del mensaje. Los modelos Transformers, gracias a su capacidad para comprender el contexto, demostraron un rendimiento sobresaliente en esta tarea.\n","\n","Utilizaremos el pipeline `text-classification` de la librería 🤗 Transformers para analizar el texto de ejemplo y visualizar el resultado de la clasificación."],"id":"a12gU1Xeq0di"},{"cell_type":"code","metadata":{"id":"fbb6MppZq0dj"},"source":["from transformers import pipeline\n","# Modelo de clasificación de texto (sentimiento) en español\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","classifier = pipeline(\"text-classification\", model=\"pysentimiento/robertuito-sentiment-analysis\")\n","import pandas as pd\n","outputs = classifier(texto)\n","pd.DataFrame(outputs)"],"id":"fbb6MppZq0dj","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZD-puqTdq0dj"},"source":["## 3. Reconocimiento de entidades nombradas (NER)\n","\n","El **Reconocimiento de Entidades Nombradas** (NER, por sus siglas en inglés) es la tarea de identificar y clasificar automáticamente nombres propios, lugares, organizaciones y otras entidades relevantes dentro de un texto. Los Transformers permiten realizar NER de manera eficiente y precisa.\n","\n","A continuación, aplicamos el pipeline `ner` al texto de ejemplo para extraer las entidades nombradas presentes."],"id":"ZD-puqTdq0dj"},{"cell_type":"code","metadata":{"id":"nyeoJh8Kq0dj"},"source":["# Modelo de reconocimiento de entidades nombradas (NER) en español\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","ner_tagger = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\", aggregation_strategy=\"simple\")\n","outputs = ner_tagger(texto)\n","pd.DataFrame(outputs)"],"id":"nyeoJh8Kq0dj","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wngEBUxYq0dj"},"source":["## 4. Respuesta a preguntas basada en contexto\n","\n","La tarea de **respuesta a preguntas** (Question Answering) consiste en responder preguntas específicas utilizando un contexto dado. Los modelos Transformers pueden comprender el texto y extraer la información relevante para responder de manera precisa.\n","\n","En el siguiente ejemplo, preguntamos al modelo qué desea el cliente, utilizando el pipeline `question-answering`."],"id":"wngEBUxYq0dj"},{"cell_type":"code","metadata":{"id":"sfCRZYcxq0dk"},"source":["# Modelo de respuesta a preguntas en español\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","reader = pipeline(\"question-answering\", model=\"PlanTL-GOB-ES/roberta-large-bne-sqac\")\n","question = \"¿Qué quiere el cliente?\"\n","outputs = reader(question=question, context=texto)\n","pd.DataFrame([outputs])"],"id":"sfCRZYcxq0dk","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O2imwRuwq0dk"},"source":["## 5. Resumen automático de texto\n","\n","El **resumen automático** permite condensar la información principal de un texto extenso en una versión más corta, manteniendo el significado esencial. Los Transformers han revolucionado esta tarea gracias a su capacidad de comprensión contextual.\n","\n","A continuación, utilizamos el pipeline `summarization` para obtener un resumen del texto de ejemplo."],"id":"O2imwRuwq0dk"},{"cell_type":"code","metadata":{"id":"5f6KQq23q0dk"},"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","resumidor = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n","resumen = resumidor(texto, max_length=80, min_length=20, do_sample=False)\n","print(resumen[0]['summary_text'])"],"id":"5f6KQq23q0dk","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"knv2k1Bbq0dk"},"source":["## 6. Traducción automática del español a inglés\n","\n","La **traducción automática** es una de las aplicaciones más destacadas de los Transformers, permitiendo traducir textos entre diferentes idiomas con alta calidad. Utilizaremos el pipeline `translation_es_to_en` para traducir el texto de ejemplo del español al inglés."],"id":"knv2k1Bbq0dk"},{"cell_type":"code","metadata":{"id":"P_8xjN6vq0dk"},"source":["# Modelo de traducción de español a inglés\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","translator = pipeline(\"translation_es_to_en\", model=\"Helsinki-NLP/opus-mt-es-en\")\n","outputs = translator(texto)\n","print(outputs[0]['translation_text'])"],"id":"P_8xjN6vq0dk","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vdr-gK_aq0dl"},"source":["## 7. Generación automática de texto (respuesta de servicio al cliente)\n","\n","La **generación automática de texto** permite crear o continuar textos de manera coherente a partir de un prompt inicial. Esta capacidad es útil, por ejemplo, para redactar respuestas automáticas en atención al cliente.\n","\n","En el siguiente ejemplo, generamos una posible respuesta de servicio al cliente utilizando el pipeline `text-generation`."],"id":"Vdr-gK_aq0dl"},{"cell_type":"code","metadata":{"id":"1LuWAKRMq0dl"},"source":["# Modelo de generación de texto en español\n","# Puedes buscar otros modelos en https://huggingface.co/models\n","generator = pipeline(\"text-generation\", model=\"datificate/gpt2-small-spanish\")\n","respuesta_inicial = \"Estimado cliente, lamentamos mucho lo ocurrido con su pedido. \"\n","prompt = texto + \"\\n\\nRespuesta del servicio al cliente:\\n\" + respuesta_inicial\n","outputs = generator(\n","    prompt,\n","    max_new_tokens=150,\n","    do_sample=True,\n","    temperature=0.7,\n","    top_k=50,\n","    top_p=0.9,\n","    repetition_penalty=1.3,\n","    eos_token_id=50256\n",")\n","print(outputs[0]['generated_text'])"],"id":"1LuWAKRMq0dl","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fwOnmW33q0dl"},"source":["---\n","\n","## Ejercicios autónomos (40 minutos)\n","\n","A continuación, te proponemos ejercicios prácticos para que pongas en práctica lo aprendido sobre la arquitectura Transformer, la librería Transformers de Hugging Face y el uso de pipelines en tareas de PLN.\n","\n","**Recorda:** Para cada ejercicio, explora la [página de modelos de Hugging Face](https://huggingface.co/models) y busca modelos que sean apropiados para español, o incluso para el contexto argentino si los encontras.\n","\n","### 1. Clasificación de textos propios\n","- Escribi dos textos breves (pueden ser opiniones, quejas o comentarios sobre servicios o productos en Argentina, por ejemplo sobre colectivos, supermercados, bancos, etc.).\n","- Busca en Hugging Face un modelo de clasificación de texto en español y usalo con el pipeline `text-classification` para analizar el sentimiento de cada texto.\n","- ¿El resultado coincide con tu expectativa? Explica brevemente.\n","\n","### 2. Reconocimiento de entidades en noticias argentinas\n","- Busca un párrafo de una noticia reciente de un medio argentino (por ejemplo, Clarín, La Nación, Página/12).\n","- Busca en Hugging Face un modelo de NER para español y aplícalo para identificar entidades nombradas.\n","- Enumera las entidades encontradas y clasifícalas (persona, organización, lugar, etc.).\n","\n","### 3. Respuesta a preguntas personalizada\n","- Escribi un pequeño texto narrativo (4-5 líneas) sobre una situación cotidiana en Buenos Aires (por ejemplo, un reclamo en una oficina pública, una experiencia en el subte, etc.).\n","- Formula dos preguntas sobre el texto y utiliza un modelo de `question-answering` de Hugging Face para responderlas.\n","- ¿Las respuestas son correctas y precisas? ¿Por qué?\n","\n","### 4. Resumen de un texto propio\n","- Elegí un texto más largo (puede ser un fragmento de Wikipedia sobre Argentina, una noticia, etc.).\n","- Busca un modelo de resumen en español en Hugging Face y úsalo con el pipeline `summarization`.\n","- Compara el resumen generado con el texto original: ¿qué información se perdió y cuál se mantuvo?\n","\n","### 5. Traducción y análisis\n","- Escribi un texto breve en español rioplatense y tradúcilo al inglés usando un modelo de traducción de Hugging Face.\n","- Luego, traduci el resultado nuevamente al español (podes usar otro pipeline o Google Translate).\n","- ¿El texto final es igual al original? ¿Qué diferencias encontras?\n","\n","### 6. Generación creativa de texto\n","- Escribe el inicio de una historia o una pregunta abierta relacionada con Buenos Aires.\n","- Busca un modelo de generación de texto en español en Hugging Face y úsalo con el pipeline `text-generation` para continuar el texto.\n","- Analiza la coherencia y creatividad de la respuesta generada.\n","\n","---\n","\n","**Tip:** Para cada ejercicio, explora la [página de modelos de Hugging Face](https://huggingface.co/models) y lee la descripción de los modelos antes de usarlos. Si tienes dudas, consulta la documentación oficial de [Transformers](https://huggingface.co/docs/transformers/index)."],"id":"fwOnmW33q0dl"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":""},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}